{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/compomics/ML-course-VIB-2024/blob/master/notebooks/Histone_marks_lr.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWoU7h5NClGi"
   },
   "source": [
    "# Histone modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Krri7AXy8UM"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "random_seed = 123\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q7DJU4Tny8Ua"
   },
   "source": [
    "# 1. The data\n",
    "\n",
    "Histone modifications play an important role in affecting gene regulation. Specific histone modifications at specific locations in or near the gene can alter the expression of genes. Predicting gene expression from histone modification signals is a widely studied research topic.\n",
    "\n",
    "In this competition you will predict gene expression levels (low=0, high=1) based on the presence of histone modifications at specific locations in the gene. You will try to find the model that learns the true underlying model best.\n",
    "\n",
    "For each gene a region of 10.000bp around the transcription start site of the gene is extracted (5000bp upstream and 5000bp downstream). This region is binned in 100 bins of 100bp. For each bin five core histone modification marks are counted [1].\n",
    "\n",
    "The dataset is compiled from the \"E047\" (Primary T CD8+ naive cells from peripheral blood) celltype from Roadmap Epigenomics Mapping Consortium (REMC) database.\n",
    "\n",
    "[1] Kundaje, A. et al. Integrative analysis of 111 reference human epige-\n",
    "nomes. Nature, 518, 317â€“330, 2015.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fEaghfDy8Ue"
   },
   "source": [
    "We start by loading the Pandas library and reading the datasets into Pandas DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "alZpE70qy8Uh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"https://raw.githubusercontent.com/compomics/ML-course-VIB-2024/refs/heads/master/data/data_train.csv\")\n",
    "test = pd.read_csv(\"https://raw.githubusercontent.com/compomics/ML-course-VIB-2024/refs/heads/master/data/data_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA6pU9qDy8U0"
   },
   "source": [
    "Let's look at a random sample of the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBIQBcTTy8U1"
   },
   "outputs": [],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ooHoxGTgCOA"
   },
   "source": [
    "An alternative visualization for this type of counting data is the heatmap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With pop we remove a column and at the same time it can be assigned to a variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qiUkeoGGMvTv"
   },
   "outputs": [],
   "source": [
    "train_ids = train.pop(\"GeneId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \".head()\" function returns the first rows of the dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FYlUkermM18o"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With \"sample\" we get a specified number of random rows back. These are visualized with the seaborn \"heatmap\" function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1lAK99coCEOR"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(30,10))\n",
    "sns.heatmap(train.sample(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYHeBhf8y8VC"
   },
   "source": [
    "The label for each datapoint is in the `Label` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZuSUhLu4L8x"
   },
   "outputs": [],
   "source": [
    "train_labels = train.pop(\"Label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VejdcRHVOXys"
   },
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LDJ7eAMch53J"
   },
   "source": [
    "Now `train` contains the feature columns only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DHXHPpo4SBG"
   },
   "source": [
    "Let's look at the number datapoints in each class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ynUhI2de6TsU"
   },
   "outputs": [],
   "source": [
    "train_labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T4eZlOyO6NNF"
   },
   "source": [
    "Let's look at `test`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDV9hz5Ay8VD"
   },
   "outputs": [],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mao3WMV3y8VJ"
   },
   "source": [
    "This is a blind test so the `Label` column is not available in the test set. The test set does contain the `GeneId` column that can be used as unique identifiers for each row in the test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n4VjbA3ey8VN"
   },
   "outputs": [],
   "source": [
    "test_index_col = test.pop(\"GeneId\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbiH1uzSy8VT"
   },
   "source": [
    "We can compute some decriptive statistics about the training set using the DataFrame `.describe()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sDAIJ23VkVWj"
   },
   "outputs": [],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UHM6V5kfEGOU"
   },
   "source": [
    "We can plot these descriptive statistics to get a general overview of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iPg1lbiWy8VV",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_description = pd.DataFrame(train.describe().transpose())\n",
    "for col in [\"count\",\"mean\",\"std\",\"min\",\"max\"]:\n",
    "    sns.histplot(train_description[col], kde=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oltcoOqH3TTD"
   },
   "source": [
    "We can use the Pandas `boxplot()` function to plot the feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjZd6rZs3ijb",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(22,8))\n",
    "train.boxplot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QsQjqutNtbP7"
   },
   "source": [
    "Let's plot these for each histone marker. Here we use a list (or set) comprehension if you want to understand this please go here: https://realpython.com/videos/understand-list-comp-overview/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gv7vShayzrR8"
   },
   "outputs": [],
   "source": [
    "marks = {m.split(\"_\")[0] for m in train.columns}\n",
    "print(marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XIwcZXHX0lO-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for mark in marks:\n",
    "    # Identify those columns that start with the mark\n",
    "    columns_selected = [c for c in train.columns if c.startswith(mark)]\n",
    "    plt.figure(figsize=(22,8))    \n",
    "    train[columns_selected].boxplot()\n",
    "    plt.title(mark)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sqPCOQL9nh8P"
   },
   "source": [
    "# 2. Our first model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qBlctuXVE5w2"
   },
   "source": [
    "Let's fit a Logistic Regression model. We will first use the very popular (with good reason) [Scikit-learn](https://scikit-learn.org/stable/) library for that.\n",
    "\n",
    "First, we hold out 20% if the training data for independant validation.\n",
    "\n",
    "Next, we fit the modelparameters on the training set and evaluate the fitted model on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "17CsBzlJlnVy"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the values in a train and validation set, for both the feature matrices and the target vector y\n",
    "train_X, val_X, train_y, val_y = train_test_split(\n",
    "    train,                                              \n",
    "    train_labels,\n",
    "    test_size=.2, \n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "# initialize the model, set number of iterations (steps) for the gradient descent\n",
    "cls = LogisticRegression(max_iter=10000)\n",
    "\n",
    "# fit the model\n",
    "cls.fit(train_X,train_y)\n",
    "\n",
    "# obtain predictions for the test and validation set\n",
    "predictions_train = cls.predict(train_X)\n",
    "predictions_val = cls.predict(val_X)\n",
    "\n",
    "print(\"Accuracy: (%f) %f\"%(accuracy_score(predictions_train, train_y),accuracy_score(predictions_val, val_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kHUh9aOCYhV8"
   },
   "outputs": [],
   "source": [
    "cls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "leHLQtnfobKd"
   },
   "source": [
    "# 3. How well does it perform in pratice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "slsToUzBojN3"
   },
   "outputs": [],
   "source": [
    "#code for submission\n",
    "predictions_test = cls.predict_proba(test)\n",
    "\n",
    "to_write = pd.DataFrame()\n",
    "to_write[\"GeneId\"] = test_index_col\n",
    "to_write[\"Label\"] = predictions_test[:,1]\n",
    "to_write.to_csv(\"submission2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9-_NuIs_r4NA"
   },
   "outputs": [],
   "source": [
    "predictions_test[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jC5nNJuqqjZm"
   },
   "source": [
    "A common metric is the log-loss, as this allows for evaluation probabilistic predictions:\n",
    "\n",
    "$$ - \\frac{1}{N} \\sum_{i=1}^N [y_{i} \\log \\, p_{i} + (1 - y_{i}) \\log \\, (1 - p_{i})],$$\n",
    "\n",
    "where $N$ is the number of datapoints, $y_i$ is the label of datapoint $i$, and $p_i$ is the prediction of the model expressed as a probability.\n",
    "\n",
    "Let's compute the log-loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u4OHuU0oqtnC"
   },
   "outputs": [],
   "source": [
    "predictions_train = cls.predict_proba(train_X)[:,1]\n",
    "predictions_val = cls.predict_proba(val_X)[:,1]\n",
    "\n",
    "print(\"Log-loss: (%f) %f\"%(log_loss(train_y,predictions_train),log_loss(val_y,predictions_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1kDGcmkU2KE5"
   },
   "source": [
    "# 4. Data pre-processing\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNCXrS1x4Tf8"
   },
   "source": [
    "Let's scale all the features to [0,1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nGkTWm904gt9"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler_minmax = preprocessing.MinMaxScaler()\n",
    "scaler_minmax.fit(train)\n",
    "train_norm = pd.DataFrame(scaler_minmax.transform(train),columns=train.columns)\n",
    "train_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KYY3fLMq5RfO"
   },
   "outputs": [],
   "source": [
    "marks = {m.split(\"_\")[0] for m in train_norm.columns}\n",
    "\n",
    "for mark in marks:\n",
    "    columns_selected = [c for c in train_norm.columns if c.startswith(mark)]\n",
    "    plt.figure(figsize=(22,8))    \n",
    "    train_norm[columns_selected].boxplot()\n",
    "    plt.title(mark)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NnhndU6_HSNc"
   },
   "source": [
    "Now, did we improve the predictions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q10qEG_4prt4"
   },
   "outputs": [],
   "source": [
    "train_norm_X, val_norm_X, train_norm_y, val_norm_y = train_test_split(train_norm,train_labels,\n",
    "                                                  test_size=.2, random_state=random_seed)\n",
    "\n",
    "cls.fit(train_norm_X,train_norm_y)\n",
    "\n",
    "predictions_norm_train = cls.predict(train_norm_X)\n",
    "predictions_norm_val = cls.predict(val_norm_X)\n",
    "\n",
    "print(\"Accuracy: (%f) %f\"%(accuracy_score(predictions_norm_train, train_norm_y),accuracy_score(predictions_norm_val, val_norm_y)))\n",
    "\n",
    "predictions_norm_train_prob = cls.predict_proba(train_norm_X)\n",
    "predictions_norm_val_prob = cls.predict_proba(val_norm_X)\n",
    "\n",
    "print(\"Log-loss: (%f) %f\"%(log_loss(train_norm_y,predictions_norm_train_prob[:,1]),log_loss(val_norm_y,predictions_norm_val_prob[:,1])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8Se-pFmtM8h"
   },
   "source": [
    "# 5. Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_6D75_dH56P"
   },
   "source": [
    "Hyperparameters are an important part of the model and need to be tuned to achieve optimal performance. Here we will use scikit-learn to perform hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PANvqYPqtJKL"
   },
   "outputs": [],
   "source": [
    "train_norm_X, val_norm_X, train_norm_y, val_norm_y = train_test_split(train_norm,train_labels,\n",
    "                                                  test_size=.2, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First lets initialize the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "log_reg = LogisticRegression(random_state=random_seed, max_iter=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuDdFLT6I4Fl"
   },
   "source": [
    "Define all hyperparameters to test, where each value of the dictionary is a hyperparameter and contains a list of values to test. You can set a specific to a single hyperparameter by defining a list with a single value (e.g., \"regularization\" : [1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yU5WTl3YxDdv"
   },
   "outputs": [],
   "source": [
    "# Define the hyperparameter grid for C\n",
    "param_grid = {'C': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10, 100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iddjK6eGJWK5"
   },
   "source": [
    "Next, we define a gridsearch object that will execute the gridsearch and a cross-validation loop to estimate performance of each hyperparameter set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wZBb1hnttNgi"
   },
   "outputs": [],
   "source": [
    "# Set up GridSearchCV with log-loss as the scoring metric\n",
    "grid_search = GridSearchCV(estimator=log_reg, param_grid=param_grid, \n",
    "                           scoring='neg_log_loss', cv=5, verbose=42, n_jobs=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gridsearch object applies an grid search on the `tune_grid` where each point in the seach space is evaluated using cross-validation:\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\"/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28zxsL3DKbc1"
   },
   "source": [
    "We can now fit the model and tune the hyperparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4r0Jur3jLAFQ"
   },
   "outputs": [],
   "source": [
    "# Fit the model on the training data\n",
    "grid_search.fit(train_norm_X, train_norm_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask the gridsearch object to return the best parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c = grid_search.best_params_['C']\n",
    "print(f\"Best C: {best_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask the gridsearch object to obtain all the CV results and the corresponding log-loss values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results from GridSearchCV\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Extract C values and their corresponding mean log-loss scores\n",
    "c_values = param_grid['C']\n",
    "mean_log_loss = -results['mean_test_score']  # Negate to get positive log-loss values\n",
    "\n",
    "# Plot C-values vs log-loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(c_values, mean_log_loss, marker='o', linestyle='-')\n",
    "plt.xscale('log')  # Logarithmic scale for C-values\n",
    "plt.xlabel('C (Inverse of Regularization Strength)', fontsize=12)\n",
    "plt.ylabel('Log-Loss (Cross-Validation)', fontsize=12)\n",
    "plt.title('Log-Loss vs C (Cross-Validation)', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a default parameters in the gridsearch object that defines that it will refit the model on all data for the best hyperparameter set. So there is no need to fit the model again for this specific best hyperparameter. We can get this fitted model by taking the \"best_estimator_\" variable from the object. Finally, lets see how this model with a tuned hyperparemeter performs on the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the validation set using log-loss\n",
    "best_model = grid_search.best_estimator_\n",
    "val_probabilities = best_model.predict_proba(val_norm_X)\n",
    "val_log_loss = log_loss(val_norm_y, val_probabilities)\n",
    "print(f\"Validation Log-Loss: {val_log_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The low-complexity of the model allows for direct interpretation of the coefficients lets see what the most important features are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mcv7TFaHVpDk"
   },
   "outputs": [],
   "source": [
    "# Retrieve the coefficients of the best model\n",
    "coefficients = best_model.coef_.flatten()  # Flatten in case there are multiple classes\n",
    "features = train_norm_X.columns\n",
    "\n",
    "# Create a DataFrame for better organization\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coefficient': coefficients\n",
    "})\n",
    "\n",
    "# Sort by absolute value of coefficients to see most influential features\n",
    "feature_importance['Abs_Coefficient'] = feature_importance['Coefficient'].abs()\n",
    "sorted_features = feature_importance.sort_values(by='Abs_Coefficient', ascending=False)\n",
    "\n",
    "# Display top 10 most important features\n",
    "top_features = sorted_features.head(10)\n",
    "print(\"Top 10 Important Features:\")\n",
    "print(top_features[['Feature', 'Coefficient']])\n",
    "\n",
    "# Bar plot of top features\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_features['Feature'], top_features['Coefficient'], color='skyblue')\n",
    "plt.xlabel('Coefficient Value', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.title('Top 10 Most Important Features in Logistic Regression', fontsize=14)\n",
    "plt.gca().invert_yaxis()  # Invert y-axis for better readability\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "Histone_marks_lr.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
